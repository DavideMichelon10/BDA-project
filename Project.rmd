---
title: "BDA - Project"
author: "Anonymous"
output: 
  pdf_document: 
    toc: yes
    toc_depth: 1
urlcolor: blue
---

```{r setup, include=FALSE}
# This chunk sets echo = TRUE as default, that is print all code.
# knitr::opts_chunk$set can be used to set other notebook generation options, too.
# include=FALSE inside curly brackets makes this block not be included in the pdf.
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}

library(pracma)
library(posterior)
library(cmdstanr)
library(rstan)
library(ggplot2)
library(loo)
library(dplyr)
library(tidyr)

cmdstanr::check_cmdstan_toolchain(fix = TRUE)

register_knitr_engine(override = FALSE)
```

# Introduction

## Motivation

## Problem

# Data

## Some EDA ----

```{r}
data = read.csv("./data/race_results_view.csv")
```

```{r}
# Data processing 
## Restricting my analysis to the period 2012-2021
data <- data %>% filter(
  position > 0,
  year > 2011
)
## convert to factors
data <- data %>% mutate(
  rider_name  = as.factor(rider_name),
  team_name  = as.factor(team_name)
)

# New variables
data <- data %>% group_by(year, sequence) %>% mutate(  
  position_prop = (n() - position) / (n() - 1),        
  prop_trans = (position_prop * (n() - 1) + 0.5) / n() 
  )
```
The variable position_prop represents how many rider_names you beat in a race, the variables position_trans is a transformation (see https://stats.stackexchange.com/a/134297/116878)

Preliminary plots


```{r}
## finish position
ggplot(data, aes(x = factor(position))) +
  geom_bar(fill = "darkmagenta") +
  labs(
    title = "Distribution of finish positions",
    subtitle = "Era (2012-2021)",
    x = "Finish position",
    y = "Count"
  )
```
Dire che non ce ne sono sempre 22 perchÃ¨ non tutti arrivano in fondo

```{r}
data %>%
  filter(rider_name %in% c("Rossi, Valentino", "Quartararo, Fabio", "Marquez, Marc", "Lorenzo, Jorge")) %>%
  ggplot(aes(x = factor(position), fill = rider_name)) +
  geom_bar(position = position_dodge(preserve = "single")) +
  scale_x_discrete(limits=rev,breaks=seq(1, 23, 3)) +
  labs(
    x = "Finish position",
    y = "Count",
    title = "Different rider's finish positions",
    subtitle = "Conditional on finishing the race",
    fill = ""
  ) +
  theme(legend.position = "top") +
  facet_wrap(~year)
```
Dire che non tutti i piloti sono sempre presenti (alcuni si ritirano, altri arrivano dopo)

```{r}
data %>%
  filter(rider_name %in% c("Rossi, Valentino", "Crutchlow, Cal", "Marquez, Marc")) %>%
  ggplot(aes(x = prop_trans, fill = rider_name)) +
  geom_density(alpha = 0.5, bw = 0.1) +
  labs(
    x = "Smoothed proportion of outperformed rider_names",
    y = "Density",
    title = "Different rider_names' results",
    subtitle = "Proportion of finished drivers outperformed",
    fill = ""
  ) +
  theme(legend.position = "top", axis.text.x = element_text(angle = 45, vjust = 0.85)) +
  facet_wrap(~year)
```

# Describtion of the models

Separate model:
$\begin{align*} y_{dc} \sim {\sf Beta}(\mu_{dc},\Phi) \\ logit(\mu_{dc}) = \beta_{d}  + \beta_{c}  \\ \beta_{d} \sim {\mathcal N}(0,10) \\  \beta_{c} \sim {\mathcal N}(0,10) \end{align*}$

Hierarchical model:
$\begin{align*} y_{dcs} \sim {\mathcal Beta}(\mu_{dcs},\Phi) \\ logit(\mu_{dcs}) = \beta_{d} + \beta_{ds} + \beta_{c} + \beta_{cs} \\ \beta_{d} \sim {\mathcal N}(0,\sigma^{2}_{d}) \\ \beta_{ds} \sim {\mathcal N}(0,\sigma^{2}_{ds}) \\ \beta_{c} \sim {\mathcal N}(0,\sigma^{2}_{c}) \\ \beta_{cs} \sim {\mathcal N}(0,\sigma^{2}_{cs}) \\ \sigma_{d} \sim {\mathcal \Gamma}(1,1) \\ \sigma_{ds} \sim {\mathcal \Gamma}(1,1) \\ \sigma_{c} \sim {\mathcal \Gamma}(1,1) \\ \sigma_{cs} \sim {\mathcal \Gamma}(1,1) \end{align*}$

## Priors

# Stan models
```{cmdstan, output.var="separate_model_d"}
data { 
  int<lower=0> N; #number of races
  int<lower=0> J_riders; 
  int<lower=0> J_teams;
  matrix[N, J_riders] y_riders;
  matrix[N, J_teams] y_teams;
}

parameters {
  matrix[J_riders,J_teams] mu; 
  
}

transformed parameters{
  
}

model {
  for (j in 1:J){
      mu[j] ~ normal(0, 10);
      sigma[j] ~ gamma(1,1);
    }
  for (j in 1:J){
    y[,j] ~ normal(mu[j], sigma[j]);
  } 
}
```

# How to build y_dc?
# Joint posterior distribution?
# How to build sigma?
# can we use brms?


https://mc-stan.org/docs/2_21/functions-reference/multivariate-normal-distribution.html


```
test_data_driver <- data.frame(
  rider_name = data$rider_name,
  posx = data$prop_trans,
  sequence = data$year*data$sequence
  
)

driver_prop <- test_data_driver %>% pivot_wider(names_from = rider_name, values_from = posx)

test_data_constr <- data.frame(
  team_name = data$team_name,
  pos = data$prop_trans,
  sequence = data$year*data$sequence
  
)

team_prop <- test_data_constr %>% pivot_wider(names_from = team_name, values_from = pos) 



for(i in c(2:ncol(team_prop))){
  temp <- team_prop[,i]
  team_prop[,i] = lapply(temp, function(x) lapply(x, mean))
}

save(team_prop,file="team_prop.Rda")
save(driver_prop,file="driver_prop.Rda")
```

```{r}
load("./team_prop.Rda")
load("./driver_prop.Rda")
```


# Rhat convergence diagnostics and interpretation

#  HMC specific convergence diagnostics

# Effective sample size diagnostic (n_eff)

# Posterior predictive checking and interpretation 

# Model comparison and interpretation of the results

# Predictive performance assessment

# Alternative priors testing

# Problems and potential improvements

# Conclusion

# Self-reflection about what the group learned 